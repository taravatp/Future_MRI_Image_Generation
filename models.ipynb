{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5Cc+VZ0U27wYD78HRokPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taravatp/Future_MRI_Image_Generation/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K0leO28AdJG0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Downconv(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,kernel_size=3,stride=1,padding=1): #stride=1 padding=1 kernel_size=3 this will be a same conv\n",
        "    super(Downconv,self).__init__() #mitooni bias ro false bezari va az batch nomr ham estefade koni\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "4rx5dU5ndsFR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class generator(nn.Module):\n",
        "  def __init__(self, in_channels=3,out_channels=3):\n",
        "    super(generator,self).__init__()\n",
        "\n",
        "    self.features = [32, 64, 128, 256]\n",
        "\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.ups = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool3d(kernel_size=2,stride=2)\n",
        "\n",
        "    for feature in self.features: \n",
        "      self.downs.append(Downconv(in_channels=in_channels,out_channels=feature)) #(3,32) - (32,64) - (64,128) - (128,256)\n",
        "      in_channels = feature\n",
        "\n",
        "    self.bottleneck = Downconv(self.features[-1], self.features[-1]*2) #(256,512)\n",
        "\n",
        "    for feature in reversed(self.features):\n",
        "      self.ups.append(\n",
        "          nn.ConvTranspose3d(in_channels=feature*2, out_channels=feature, kernel_size=2, stride=2) #double the heigh and width of the image\n",
        "      )\n",
        "      self.ups.append(Downconv(in_channels=feature*2,out_channels=feature))\n",
        "    \n",
        "    self.final_conv = nn.Conv3d(self.features[0],out_channels,kernel_size=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    \n",
        "    skip_connections = []\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.bottleneck(x)\n",
        "\n",
        "    skip_connections = skip_connections[::-1]\n",
        "    for index in range(0,len(self.ups),2):\n",
        "      x = self.ups[index](x) #0,2,4,.. #upsampling\n",
        "      skip_connection = skip_connections[index//2] #0,1,2,///\n",
        "      concat_skip = torch.cat((skip_connection,x),dim=1) #concatanating\n",
        "      x = self.ups[index+1](concat_skip) #applying double convolutions\n",
        "\n",
        "    x = self.final_conv(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pcI__CQtdfLP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  model = generator()\n",
        "  input = torch.zeros((1,3,64,64,64)) #(N, c, D , H, W)\n",
        "  print('input shape:',input.shape)\n",
        "  out = model(input)\n",
        "  print('output shape:',out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ7l73RLUxji",
        "outputId": "e75be012-01c1-40eb-c60e-dca8aaf4b7cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([1, 3, 64, 64, 64])\n",
            "output shape: torch.Size([1, 3, 64, 64, 64])\n"
          ]
        }
      ]
    }
  ]
}